{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tutorial5_Createing Models.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMXph53LnGffR6W179C9NZq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tatsuro0726/chemoinfomatics/blob/main/deepchem/Tutorial5_Createing_Models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PsuBWDjXrHm9"
      },
      "source": [
        "#### Tutorial Part 5: Creating Models with TensorFlow and PyTorch\r\n",
        "これまでのチュートリアルでは、DeepChemが提供する標準モデルを使用してきました。これは多くのアプリケーションには適していますが、遅かれ早かれ、自分で定義したアーキテクチャで全く新しいモデルを作成したいと思うでしょう。DeepChemは、TensorFlow（Keras）とPyTorchの両方との統合を提供しているので、これらのフレームワークのいずれかのモデルで使用することができます。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uBO1VoVerQqL"
      },
      "source": [
        "#### Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ZORAHX_q-jZ",
        "outputId": "0bfece9b-61d0-4f06-bd12-71248b2feb23"
      },
      "source": [
        "!curl -Lo conda_installer.py https://raw.githubusercontent.com/deepchem/deepchem/master/scripts/colab_install.py\r\n",
        "import conda_installer\r\n",
        "conda_installer.install()\r\n",
        "!/root/miniconda/bin/conda info -e"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  3490  100  3490    0     0  15043      0 --:--:-- --:--:-- --:--:-- 15043\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "add /root/miniconda/lib/python3.6/site-packages to PYTHONPATH\n",
            "python version: 3.6.9\n",
            "fetching installer from https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
            "done\n",
            "installing miniconda to /root/miniconda\n",
            "done\n",
            "installing rdkit, openmm, pdbfixer\n",
            "added conda-forge to channels\n",
            "added omnia to channels\n",
            "done\n",
            "conda packages installation finished!\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "# conda environments:\n",
            "#\n",
            "base                  *  /root/miniconda\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5GBBnJ8urSo8",
        "outputId": "b6e12ddf-ad23-4659-fc88-0af30b1b0ee6"
      },
      "source": [
        "!pip install --pre deepchem"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting deepchem\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b7/f7/5828211eb0b9a78e4dad42de96dcc61d616330586c28fceda6651d8ae324/deepchem-2.5.0.dev20210116000740-py3-none-any.whl (531kB)\n",
            "\r\u001b[K     |▋                               | 10kB 11.8MB/s eta 0:00:01\r\u001b[K     |█▎                              | 20kB 17.2MB/s eta 0:00:01\r\u001b[K     |█▉                              | 30kB 20.8MB/s eta 0:00:01\r\u001b[K     |██▌                             | 40kB 13.2MB/s eta 0:00:01\r\u001b[K     |███                             | 51kB 9.0MB/s eta 0:00:01\r\u001b[K     |███▊                            | 61kB 7.9MB/s eta 0:00:01\r\u001b[K     |████▎                           | 71kB 8.5MB/s eta 0:00:01\r\u001b[K     |█████                           | 81kB 9.3MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 92kB 9.2MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 102kB 9.4MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 112kB 9.4MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 122kB 9.4MB/s eta 0:00:01\r\u001b[K     |████████                        | 133kB 9.4MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 143kB 9.4MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 153kB 9.4MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 163kB 9.4MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 174kB 9.4MB/s eta 0:00:01\r\u001b[K     |███████████                     | 184kB 9.4MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 194kB 9.4MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 204kB 9.4MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 215kB 9.4MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 225kB 9.4MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 235kB 9.4MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 245kB 9.4MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 256kB 9.4MB/s eta 0:00:01\r\u001b[K     |████████████████                | 266kB 9.4MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 276kB 9.4MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 286kB 9.4MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 296kB 9.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 307kB 9.4MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 317kB 9.4MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 327kB 9.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 337kB 9.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 348kB 9.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 358kB 9.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 368kB 9.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 378kB 9.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 389kB 9.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 399kB 9.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 409kB 9.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 419kB 9.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 430kB 9.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 440kB 9.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 450kB 9.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 460kB 9.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 471kB 9.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 481kB 9.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 491kB 9.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 501kB 9.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 512kB 9.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 522kB 9.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 532kB 9.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from deepchem) (1.4.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from deepchem) (1.1.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from deepchem) (1.19.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from deepchem) (0.22.2.post1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from deepchem) (1.0.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->deepchem) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas->deepchem) (2.8.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.7.3->pandas->deepchem) (1.15.0)\n",
            "Installing collected packages: deepchem\n",
            "Successfully installed deepchem-2.5.0.dev20210116000740\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "It2eD8SJsrAE"
      },
      "source": [
        "#### Keras Model\r\n",
        "Keras Modelは、DeepchemのModelクラスのサブクラス。\r\n",
        "tensorflow.keras.Modelのラッパーとして動作する。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLlK6II7sbkC"
      },
      "source": [
        "import deepchem as dc\r\n",
        "import tensorflow as tf\r\n",
        "\r\n",
        "# kerasのモデル構築\r\n",
        "keras_model = tf.keras.Sequential([\r\n",
        "                  tf.keras.layers.Dense(1000, activation='relu'),\r\n",
        "                  tf.keras.layers.Dropout(rate=0.5),\r\n",
        "                  tf.keras.layers.Dense(1)\r\n",
        "])\r\n",
        "\r\n",
        "# Deepchemでラップ\r\n",
        "model = dc.models.KerasModel(keras_model,dc.models.losses.L2Loss())"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NATB_2yntdPd",
        "outputId": "fd45cd14-d333-4a60-8101-2fc361ab6d57"
      },
      "source": [
        "# data読み込み\r\n",
        "tasks, datasets, transformers = dc.molnet.load_delaney(featurizer='ECFP', splitter='random')\r\n",
        "# datasetsの展開\r\n",
        "train, valid, test = datasets\r\n",
        "\r\n",
        "# モデルの学習\r\n",
        "model.fit(train, nb_epoch=50)\r\n",
        "metric = dc.metrics.Metric(dc.metrics.pearson_r2_score) # モデルの評価指標\r\n",
        "print('training set score: {}'.format(model.evaluate(train, [metric])))\r\n",
        "print('test set score: {}'.format(model.evaluate(test, [metric])))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training set score: {'pearson_r2_score': 0.9793306697760502}\n",
            "test set score: {'pearson_r2_score': 0.6481987386001775}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W7LDJ4osuxNq"
      },
      "source": [
        "#### Torch Model\r\n",
        "torch.nn.Moduleをラップ。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GQEaZNlbuTKc",
        "outputId": "4515fc27-f6d5-4d59-bae1-7bcc95eb8fe0"
      },
      "source": [
        "import torch\r\n",
        "\r\n",
        "pytorch_model = torch.nn.Sequential(\r\n",
        "                torch.nn.Linear(1024, 1000),\r\n",
        "                torch.nn.ReLU(),\r\n",
        "                torch.nn.Dropout(0.5),\r\n",
        "                torch.nn.Linear(1000,1)\r\n",
        ")\r\n",
        "model = dc.models.TorchModel(pytorch_model, dc.models.losses.L2Loss())\r\n",
        "\r\n",
        "model.fit(train, nb_epoch=50)\r\n",
        "print('training set score: {}'.format(model.evaluate(train, [metric])))\r\n",
        "print('test set score: {}'.format(model.evaluate(test, [metric])))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training set score: {'pearson_r2_score': 0.9790883000176276}\n",
            "test set score: {'pearson_r2_score': 0.6357919894732449}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2h8GG5D8wcdB"
      },
      "source": [
        "#### 損失を計算する\r\n",
        "より発展した例の紹介。  \r\n",
        "確率分布を出力するモデルを考えてみる。  \r\n",
        "確率とlogitの両方を返すモデルを作成する。  \r\n",
        "KerasModelとTorchModelでは「output types」のリストを指定することが可能。特定の出力がpredictionを持っている場合, prediction()を呼び出した時に返されるべき通常の出力であることを意味する。lossを持っている場合、出力の代わりに損失関数に渡されることを意味する。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ZlxqukRu8pu"
      },
      "source": [
        "class ClassificationModel(tf.keras.Model):\r\n",
        "\r\n",
        "    def __init__(self):\r\n",
        "        super(ClassificationModel, self).__init__()\r\n",
        "        self.dense1 = tf.keras.layers.Dense(1000, activation='relu')\r\n",
        "        self.dense2 = tf.keras.layers.Dense(1)\r\n",
        "\r\n",
        "    def call(self, inputs, training=False):\r\n",
        "        y = self.dense1(inputs)\r\n",
        "        if training:\r\n",
        "            y = tf.nn.dropout(y, 0.5)\r\n",
        "        logits = self.dense2(y)\r\n",
        "        output = tf.nn.sigmoid(logits)\r\n",
        "        return output, logits\r\n",
        "\r\n",
        "keras_model = ClassificationModel()\r\n",
        "output_types = ['prediction', 'loss']\r\n",
        "model = dc.models.KerasModel(keras_model, dc.models.losses.SigmoidCrossEntropy(), output_types=output_types)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bm9kW2HrylzW",
        "outputId": "97ebdd71-2013-44ee-c755-1e305fd19455"
      },
      "source": [
        "# baceデータの読み込み\r\n",
        "tasks, datasets, transformers = dc.molnet.load_bace_classification(featurizer='ECFP', split='scaffold')\r\n",
        "train, valid, test = datasets\r\n",
        "model.fit(train, nb_epoch=100)\r\n",
        "metric = dc.metrics.Metric(dc.metrics.roc_auc_score)\r\n",
        "print('training set score: {}'.format(model.evaluate(train, [metric])))\r\n",
        "print('test set score: {}'.format(model.evaluate(test, [metric])))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'split' is deprecated.  Use 'splitter' instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "training set score: {'roc_auc_score': 0.9996116504854369}\n",
            "test set score: {'roc_auc_score': 0.7567934782608696}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pa0S7CNTz1tz"
      },
      "source": [
        "* トレーニング中のチェックポイントを自動的に保存。\r\n",
        "* Logging progress to the console, to TensorBoard, or to Weights & Biases.\r\n",
        "* f(outputs, labels, weights)形式の関数で定義したカスタム損失関数\r\n",
        "* ValidationCallbackクラスを使用した早期停止。\r\n",
        "* 事前に訓練されたモデルからのパラメータのロード\r\n",
        "* モデル出力の不確実性の推定\r\n",
        "* サリエンシーマッピングによる重要な特徴の識別\r\n",
        "    - reference; https://keisen.github.io/keras-vis-docs-ja/visualizations/saliency/#_1\r\n",
        "    - example: https://github.com/raghakot/keras-vis/tree/master/examples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mvGCJfepzVTG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}